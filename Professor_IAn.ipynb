{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonathanFSP/Projeto_Imersao_Alura/blob/main/Professor_IAn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5OqBLjbaSSge"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hNIaq8s0SZmC"
      },
      "outputs": [],
      "source": [
        "#ImportaÃ§Ã£o de bibliotecas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get ('SECRET_KEY')\n",
        "genai.configure(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "swG9GAtRkWyz",
        "outputId": "8d4396e0-719a-4a7c-f41d-fdc1cf06ea9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ],
      "source": [
        "for m in genai.list_models():\n",
        "    if 'generateContent' in m.supported_generation_methods:\n",
        "        print(m.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0pS6G7cGvh1S"
      },
      "outputs": [],
      "source": [
        "generation_config = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.2, #aleatoriedade das palavras de 0 Ã  1\n",
        "}\n",
        "\n",
        "# NONE, FEW, SOME, MOST\n",
        "safety_settings = {\n",
        "    \"HARASSMENT\": \"block_none\",\n",
        "    \"HATE\": \"block_none\",\n",
        "    \"SEXUAL\": \"block_none\",\n",
        "    \"DANGEROUS\": \"block_none\"\n",
        "}\n",
        "\n",
        "#escolhendo e inicializando o modelo com as configuraÃ§Ãµes\n",
        "model = genai.GenerativeModel (model_name = \"gemini-1.0-pro\",\n",
        "                                generation_config=generation_config,\n",
        "                               safety_settings = safety_settings)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from termcolor import colored\n",
        "\n",
        "def conversar_com_especialista_IA():\n",
        "    \"\"\"\n",
        "    Conversa com a IA como especialista em um tema especÃ­fico.\n",
        "    Returns:\n",
        "        None. Imprime a conversa no console.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(colored(\"\\n-- Bem-vindo ao Chat, sou o professor IAn! --\", \"blue\", attrs=[\"bold\"]))\n",
        "        print(colored(\"OlÃ¡! ðŸ‘‹ Sou seu especialista em IA. Vamos conversar sobre o que vocÃª quiser.\\n\", \"cyan\"))\n",
        "\n",
        "        tema = input(\"Qual tema te interessa hoje? \")\n",
        "\n",
        "        print(colored(f\"\\n## Tema: {tema.upper()} ##\\n\", \"blue\", attrs=[\"bold\"]))\n",
        "        print(colored(\"Qual o seu nÃ­vel de conhecimento em {}?\\n\".format(tema), \"cyan\"))\n",
        "        print(colored(\"1 - Iniciante (apenas comeÃ§ando) ðŸ‘¶\", \"yellow\"))\n",
        "        print(colored(\"2 - IntermediÃ¡rio (jÃ¡ tenho alguma base) ðŸ“š\", \"green\"))\n",
        "        print(colored(\"3 - Especialista (conheÃ§o o tema a fundo) ðŸ¤“\", \"blue\"))\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                nivel = int(input(\"Escolha uma opÃ§Ã£o (1-3): \"))\n",
        "                if 1 <= nivel <= 3:\n",
        "                    break\n",
        "                else:\n",
        "                    print(colored(\"OpÃ§Ã£o invÃ¡lida. Escolha um nÃºmero entre 1 e 3.\", \"red\"))\n",
        "            except ValueError:\n",
        "                print(colored(\"OpÃ§Ã£o invÃ¡lida. Digite um nÃºmero.\", \"red\"))\n",
        "\n",
        "        niveis = [\"iniciante\", \"intermediÃ¡rio\", \"especialista\"]\n",
        "        nivel = niveis[nivel - 1]\n",
        "        introducao = f\"Ok, vamos lÃ¡! Sou um {nivel} em {tema}. \"\n",
        "\n",
        "        if nivel == \"iniciante\":\n",
        "            introducao += \"Explique os conceitos bÃ¡sicos com exemplos, por favor.\"\n",
        "        elif nivel == \"intermediÃ¡rio\":\n",
        "            introducao += \"Aprofunde as explicaÃ§Ãµes e mostre as relaÃ§Ãµes com outras Ã¡reas.\"\n",
        "        elif nivel == \"especialista\":\n",
        "            introducao += \"Compartilhe insights sobre os desafios do tema e discuta diferentes abordagens.\"\n",
        "\n",
        "        chat = genai.ChatSession(model=model)\n",
        "        chat.send_message(introducao)\n",
        "\n",
        "        while True:\n",
        "            print(colored(\"\\n--- FaÃ§a sua pergunta ---\\n\", \"blue\", attrs=[\"bold\"]))\n",
        "            duvida = input(\"Sua pergunta: \")\n",
        "            if duvida.strip().lower() == 'fim':\n",
        "                print(colored(\"\\n--- Fim da conversa ---\\n\", \"blue\", attrs=[\"bold\"]))\n",
        "                print(colored(\"Foi um prazer conversar com vocÃª! ðŸ˜Š AtÃ© a prÃ³xima.\", \"cyan\"))\n",
        "                return  # Encerra a sessÃ£o\n",
        "\n",
        "            response = chat.send_message(duvida)\n",
        "            print(colored(\"\\nResposta da IA:\\n\", \"blue\"), response.text)\n",
        "\n",
        "            print(colored(\"\\n--- O que vocÃª deseja fazer agora? ---\\n\", \"blue\", attrs=[\"bold\"]))\n",
        "            print(colored(\"1 - Fazer outra pergunta â“\", \"yellow\"))\n",
        "            print(colored(\"2 - Testar meus conhecimentos com um quiz ðŸ§ \", \"green\"))\n",
        "            print(colored(\"3 - Escolher um novo tema ðŸ’¡\", \"blue\"))\n",
        "            print(colored(\"4 - Finalizar a conversa ðŸ‘‹\", \"red\"))\n",
        "\n",
        "            while True:\n",
        "                try:\n",
        "                    opcao = int(input(\"Escolha uma opÃ§Ã£o (1-4): \"))\n",
        "                    if opcao in range(1, 5):\n",
        "                        break\n",
        "                    else:\n",
        "                        print(colored(\"OpÃ§Ã£o invÃ¡lida. Escolha um nÃºmero entre 1 e 4.\", \"red\"))\n",
        "                except ValueError:\n",
        "                    print(colored(\"OpÃ§Ã£o invÃ¡lida. Digite um nÃºmero.\", \"red\"))\n",
        "\n",
        "            if opcao == 1:\n",
        "                continue  # Continua no mesmo assunto\n",
        "            elif opcao == 2:\n",
        "                fazer_quiz(tema, chat, duvida)\n",
        "                break  # Sai do loop de perguntas apÃ³s o quiz\n",
        "            elif opcao == 3:\n",
        "                conversar_com_especialista_IA()\n",
        "                return  # Encerra a sessÃ£o apÃ³s reiniciar\n",
        "            elif opcao == 4:\n",
        "                print(colored(\"\\n--- Fim da conversa ---\\n\", \"blue\", attrs=[\"bold\"]))\n",
        "                print(colored(\"Foi um prazer conversar com vocÃª! ðŸ˜Š AtÃ© a prÃ³xima.\", \"cyan\"))\n",
        "                return  # Encerra a sessÃ£o\n",
        "\n",
        "    except Exception as e:\n",
        "        print(colored(\"\\n--- Oops! Algo deu errado ---\\n\", \"red\", attrs=[\"bold\"]))\n",
        "        print(colored(\"Parece que encontramos um problema. NÃ£o se preocupe, estamos trabalhando para resolver! ðŸ˜Š Por favor, tente novamente mais tarde.\", \"red\"))\n",
        "        print(colored(f\"Detalhes do erro (para nerds): {e}\", \"red\"))\n",
        "\n",
        "def fazer_quiz(tema, chat, duvida):\n",
        "    \"\"\"\n",
        "    Cria e administra um quiz com perguntas sobre o tema, uma de cada vez.\n",
        "    Args:\n",
        "        tema: O tema do quiz.\n",
        "        chat: A sessÃ£o de chat com o modelo Gemini.\n",
        "        duvida: A dÃºvida especÃ­fica do usuÃ¡rio.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(colored(\"\\n## QUIZ ##\\n\", \"green\", attrs=[\"bold\"]))\n",
        "        print(colored(f\"Que tal testar seus conhecimentos sobre {tema} com um quiz rÃ¡pido? ðŸ§ \\n\", \"green\"))\n",
        "\n",
        "        while True:\n",
        "            num_perguntas = 0\n",
        "            while True:\n",
        "                num_perguntas += 1\n",
        "                prompt_quiz = f\"Crie uma pergunta de mÃºltipla escolha sobre {tema}, focando em '{duvida}', com 4 opÃ§Ãµes de resposta (A, B, C, D), sem mostrar a resposta correta.\"\n",
        "                response = chat.send_message(prompt_quiz)\n",
        "                print(colored(f\"\\nPergunta {num_perguntas}:\\n\", \"blue\"))\n",
        "                print(response.text)\n",
        "                resposta_usuario = input(\"Qual sua resposta (A, B, C ou D)? \").upper()\n",
        "                prompt_resposta = f\"A resposta correta para a pergunta '{response.text}' Ã© a '{resposta_usuario}'? Por que?\"\n",
        "                print(colored(\"\\nResposta:\\n\", \"blue\"), chat.send_message(prompt_resposta).text)\n",
        "\n",
        "                resposta_continuar = input(colored(\"\\nQuer tentar outra pergunta (sim/nÃ£o)? ðŸ¤”\\n\", \"cyan\")).lower()\n",
        "                if resposta_continuar != \"sim\":\n",
        "                    break\n",
        "\n",
        "            print(colored(\"\\n--- Fim do Quiz ---\\n\", \"green\", attrs=[\"bold\"]))\n",
        "            print(colored(\"Espero que tenha se saÃ­do bem! ðŸŽ‰\\n\", \"green\"))\n",
        "            break\n",
        "\n",
        "    except Exception as e:\n",
        "        print(colored(\"\\n--- Oops! Algo deu errado ---\\n\", \"red\", attrs=[\"bold\"]))\n",
        "        print(colored(\"Parece que encontramos um problema no quiz. NÃ£o se preocupe, estamos trabalhando para resolver! ðŸ˜Š Por favor, tente novamente mais tarde.\", \"red\"))\n",
        "        print(colored(f\"Detalhes do erro (para nerds): {e}\", \"red\"))\n",
        "\n",
        "# Inicia a conversa\n",
        "conversar_com_especialista_IA()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsBFD9te3bOP",
        "outputId": "b44d5b36-997c-4ebb-b2c3-05d7512a392d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- Bem-vindo ao Chat, sou o professor IAn! --\n",
            "OlÃ¡! ðŸ‘‹ Sou seu especialista em IA. Vamos conversar sobre o que vocÃª quiser.\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdh4eQSjnzbgjxVftJ7Mo4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}